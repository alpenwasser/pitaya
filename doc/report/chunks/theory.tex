% ==============================================================================
%
%                 T H E O R E T I C A L   B A C K G R O U N D
%
% ==============================================================================
\chapter{Theoretical Background} % ------------------------------------------- %
\label{ch:theory}
% ---------------------------------------------------------------------------- %
% ==============================================================================
%
%                               O V E R V I E W
%
% ==============================================================================

This  chapter presents  a  brief  synopsis on  some  aspects  of digital  data
acquisition from  an analog source  and the processing  of that data,  and how
those issues pertain to our project. It  is not intended to be a comprehensive
treatise on the subject but shall serve  as a short refresher. At its end, the
reader should  have sufficient insight  to understand the basic  motivation of
our project from a theoretical point of view.

% ==============================================================================
%
%                              D S P   C H A I N
%
% ==============================================================================
\section{The Digital Signal Processing Chain}% <<< --------------------------- %
\label{sec:dsp_chain}
% ---------------------------------------------------------------------------- %

Digitally acquiring a signal generally requires at least the following steps:
\begin{itemize}\tightlist
        \item
            Passing the signal through an analog low-pass filter.
        \item
            Sampling and quantizing the filtered signal.
\end{itemize}

The   resulting   sequence  of   values   can   then  be   further   digitally
processed. The necessary  building blocks  for this  process are  portrayed in
Figure~\ref{fig:dspChain:blocks}.

\begin{figure}
    \centering
    \input{images/dspChain/dspChain.tikz}
    \caption[The DSP Chain]{%
        The  basic  building   blocks  of  the  DSP  chain   from  its  analog
        input  to its  digitally processed  output.  From  left to  right: The
        analog  low-pass filter  (\emph{LP}), the  analog-to-digital converter
        (\emph{ADC}), and  an arbitrary  digital signal processing  system for
        further processing of the ADC's output (\emph{DSP}).%
    }
    \label{fig:dspChain:blocks}
\end{figure}

\begin{figure}
    \centering
    \input{images/dspChain/timeDomain.tikz}
    \input{images/dspChain/freqDomain.tikz}
    \caption[Signals Passing Through the DSP Chain (Simplified)]{%
        Simplified  time-domain  (top)   and  frequency-domain  (bottom)  view
        of  the  signal  at  different  stages on  its  way  through  the  DSP
        chain. The  circled  numbers  correspond  to the  stages  as  outlined
        in  Figure~\ref{fig:dspChain:blocks}.  Stage  1 is  the signal  before
        passing through the  input low-pass filter, with  a significant amount
        of  high-frequency noise. The  low-pass filter  removes any  frequency
        components  above ${f_s}/{2}$  in an  ideal scenario  (in reality,  it
        merely attenuates them, as we will see later), resulting in the signal
        at  stage  2.\protect\newline  After  having been  filtered,  the  ADC
        samples and  quantizes the signal,  yielding a sequence of  values, as
        schematically portrayed  in the rightmost  picture for stage  3.  Note
        that due to the sampling process,  the spectrum of the filtered signal
        is repeated at intervals of $f_s$. This  is the source of the issue of
        \emph{aliasing}.%
    }
    \label{fig:dspChain:signals}
\end{figure}

Of particular  interest for our  application is  what happens in  the ADC. The
quantization process converts a  value-continuous signal into a value-discreet
one,  with its  resolution being  a specification  of the  ADC which  is being
used. As an example, the ADC in our system has a resolution of \num{14}\,bits,
meaning it can divide its valid  input range into \num{16384} values. Given an
input  range of  \SI{2}{\volt_\mathrm{PP}}, this  equates to  a resolution  of
roughly \SI{122}{\micro\volt}  (in theory). This  quantization process  is the
source of what is generally known as \emph{quantization noise}.

Besides the quantization,  the other step happening in the  ADC is sampling; a
time-continuous signal is converted into a series of time-discreet values. The
time between those values is known as \emph{sampling time}, its inverse is the
\emph{sampling  frequency}. Note that  usually  these are  constant, at  least
during the  time where the signal  is measured. This need not  strictly be the
case  in theory  though. In our  system, this  sampling frequency  is a  fixed
property of the ADC, and is \SI{125}{\mega\hertz}.

The sampling  step lies  at the  core of  the problem  our project  intends to
address:  \emph{aliasing}. Therefore, we  will take  a  closer look  at a  few
consequences  of the  sampling  process, and  how they  are  relevant to  this
project.

Descriptively, the sampling  process can be thought of as  looking at a signal
at  specific points  in  time and  capturing  its value. Mathematically,  this
amounts to multiplying  the signal with a  series of Dirac pulses  in the time
domain,  and  convolving with  a  series  of  Dirac  pulses in  the  frequency
domain\footnotemark.
\footnotetext{%
    \emph{Pro memoria}: A series of Dirac pulses  in the time domain has as its
    spectrum a series of Dirac pulses as well.%
}.
This  convolution  in   the  frequency  domain  lies  at  the   heart  of  the
problem   of  aliasing,   because  it   results  in   the  incoming   signal's
spectrum  being  repeated  at  intervals  of  $f_s$  (see  also:  stage  3  in
Figure~\ref{fig:dspChain:signals}). This is no problem as long as the spectrum
of the incoming signal fits within  the boundaries set by this repetition. But
if  the  spectrum   of  the  incoming  signal  is  too   broad,  two  or  more
recurrences  of  the spectrum  will  overlap. This  effect is  highlighted  in
Figure~\ref{fig:aliasing:band}.

\begin{figure}
    \centering
    \input{images/aliasing/band.tikz}
    \caption[Aliasing Illustrated via Signal Frequency Band]{%
        Simplified view  of a signal  which does not produce  aliasing between
        its recurrences  in the  frequency spectrum  (top), contrasted  with a
        signal whose  frequency band  has components  above half  the sampling
        frequency,  resulting   in  aliasing;  its  spectral   copies  overlap
        (highlighted areas in the bottom plot).%
    }
    \label{fig:aliasing:band}
\end{figure}

This overlap results in two primary problems:
\begin{itemize}\tightlist
    \item
        The digital  signal may not  be unambiguously reconstructable  into an
        analog signal, if that is intended.
    \item
        Frequencies  may occur  in the  digital  signal stream  which are  not
        actually  present  in  the  original  signal. This  problem  is  often
        referred to  as the  \emph{folding back} of  frequency components. See
        Figure~\ref{fig:aliasing:dirac} for an illustration  of how this might
        look.

        This problem is of particular interest  to our application, as we will
        see later.
\end{itemize}

\begin{figure}
    \centering
    \input{images/aliasing/dirac.tikz}
    \caption[Aliasing With Harmonic Signals]{%
        Example of  two harmonic signals  being sampled. In the top  plot, the
        signal's frequency is  below half the sampling frequency  and there is
        no aliasing. The  signal can be  reconstructed without error.   In the
        bottom  plot,  the  signal's  frequency is  above  half  the  sampling
        frequency. Consequently, the copies of the signal's frequency spectrum
        centered around  the sampling  frequency and  its negative  alias back
        into  the  band  between  $-f_s/2$  and  $f_s/2$. If  this  signal  is
        reconstructed, the resulting  signal would have a frequency  of $f_s -
        f_{\mathrm{sig}}$ instead of $f_{\mathrm{sig}}$.%
    }
    \label{fig:aliasing:dirac}
\end{figure}


Once a signal  has left the ADC and  is handed down the DSP  chain for further
processing,  the primary  problem becomes  one of  resources, particularly  in
real-time applications. In  most systems,  the available  hardware is  a fixed
constraint, and depending on what sort of processing is to be conducted on the
digital data stream, the available resources may or may not suffice.

If available resources are found to be insufficient for real-time processing of
the data stream, one may choose to
\begin{itemize}\tightlist
    \item
        not process the data in real time,
    \item
        reduce the complexity of the computations, or
    \item
        reduce the amount of data to be processed through \emph{downsampling}
        of the signal.
\end{itemize}
The  last case  is the  route  which is  chosen in  our application. The  main
constraint on the Red Pitaya is that  the data being generated cannot be moved
off the device in  real time, and the device itself  does not offer sufficient
storage for capturing a meaningful amount of data which can then be moved onto
another device for  further processing at a later  point. Therefore the amount
of data must  be reduced before it can  be moved off the device  to a computer
for viewing or further processing (see Section~\ref{sec:requirements}).

Because downsampling a signal is in  essence nothing more than the sampling of
a signal which has already been sampled, a lot of the considerations which are
valid for the  step from an analog  to a digital signal as  outlined above are
either very  similar or even identical. Specifically,  the same considerations
for  aliasing still  apply: If  the  signal which  is  to  be downsampled  has
frequency components  above $f_{s,  downsampled}/2$, aliasing  will occur. And
since  the signal  coming out  of  the ADC  has the  analog signal's  spectrum
(filtered by the analog lowpass before  the ADC) recurring at intervals of the
ADC's sampling frequency, this is always the case.

Therefore,  the sampled  signal must  be  filtered through  a low-pass  filter
before  being downsampled,  just as  the original  analog signal  was low-pass
filtered  before being  passed into  the  ADC. In light  of the  signal to  be
downsampled  being a  \emph{digital} signal  instead  of an  analog one,  that
low-pass filter must  naturally be a digital filter as  well. Designing such a
digital low-pass filter is the core mission of this project.

The key properties of such a filter which are relevant to our application are
\begin{itemize}\tightlist
    \item
        its transition band width (filter steepness), and
    \item
        its aliasing attenuation.
\end{itemize}
The aliasing attenuation refers  to the fact that when a  filter is being used
for  downsampling,  copies  of  its  frequency response  will  be  created  at
intervals  of the  lower  sampling  rate (analogous  to  the sampling  process
producing spectral copies of a signal when sampling an analog signal).

The stopband  components of these  copies overlap with the  intended passband,
leading to aliasing  (it should be noted that this  phenomenon is also present
in the  case of  the analog input  filter for the  DSP chain). This  effect is
portrayed  in  Figure~\ref{fig:aliasing:iirCopies}. The  top  plot  shows  the
filter's frequency response  along with four copies to  illustrate the overlap
effect. The bottom plot shows the aliasing effect more clearly by removing the
spectral copies and retaining the aliased regions.

The overlapping parts of the spectrum  are composed of spectral copies both to
the right  and left side of  the original. Therefore, the aliased  regions are
alternately flipped around the vertical axis. This creates in essence the same
effect  as if  the paper  were folded  along multiples  of the  lower sampling
rate  over the  frequency  range of  the  central  copy (in  the  case of  our
example: $0.2f_s$, $0.4f_s$, $0.6f_s$ and $0.8f_s$) like an accordion. This is
where the term \emph{folding back} originates.

\begin{figure}
    \centering
    \input{images/aliasing/iirCopies.tikz}
    \caption[Folding Back of Stopband Components Into Passband]{%
        The phenomenon  of folding back  when downsampling, illustrated  for a
        lowpass IIR  filter with a  cutoff frequency  of $0.2\cdot f_s$  for a
        downsampling ratio of $R=5$.  The downsampling process produces copies
        of the filter's frequency response  at intervals of the lower sampling
        frequency, visible  in the  top plot.  The  stopbands of  these copies
        then  overlap with  the intended  passband.  The  bottom plot  shows a
        close-up view with the spectral copies for clarity.%
    }
    \label{fig:aliasing:iirCopies}
\end{figure}

%>>>
% ==============================================================================
%
%                        D I G I T A L   F I L T E R S
%
% ==============================================================================
\section{Digital Filters}% <<< ----------------------------------------------- %
\label{sec:digital_filters}
% ---------------------------------------------------------------------------- %

Digital filters can  be distinguished by several  characteristics; common ways
to  categorize them  are by  topology,  impulse response  and their  frequency
response. There  are  two commonly  used  types  of digital  filters: Infinite
impulse   response   (IIR)  filters   and   finite   impulse  response   (FIR)
filters. Another important class of filters are cascaded integrator-comb (CIC)
filters,  however, in  the strictest  sense they  are a  special class  of FIR
filters rather than an entirely new  type of LTI system~\cite{1163535}.  While
our system uses FIR and CIC filters,  a brief overview of IIR filters is still
presented here, for the sake of completeness.
% ==============================================================================
%
%                        I I R   F I L T E R S
%
% ==============================================================================
\subsection{IIR Filters} %<<< ------------------------------------------------ %
\label{subsec:iir_filters}
% ---------------------------------------------------------------------------- %

Infinite impulse response filters are  so named because their impulse response
continues  into perpetuity,  never  reaching zero. In  practice, the  response
usually comes  sufficiently close to  zero at a certain  point that it  can be
considered zero for most intents and purposes.

IIR filters have feedback paths, resulting  in a filter response equation with
non-trivial  denominator components. Their  basic  building  blocks are  delay
elements, multipliers and adders.

\begin{equation}
    \label{eq:iir_filter}
    H(z) = \frac{%
            \sum_{k=0}^N b_k \cdot z^{-k}}{%
            1 + \sum_{i=0}^M a_i \cdot z^{-i}}
\end{equation}

IIR filters generally require a lower order (and therefore fewer resources) to
approximate a  certain frequency  response specification  than FIR  filters do
(particularly the constraint of a narrow transition band), but this comes at a
cost:  IIR  filters have a  non-linear phase response;  linear-phase responses
can only  be approximated. Furthermore, IIR  filters are not guaranteed  to be
BIBO stable due to their feedback paths.

\begin{figure}
    \centering
    \input{images/filtertopologies/iir.tikz}
    \caption[IIR Filter: Biquad]{Example of an IIR filter topology for a biquad}
    \label{fig:filtertopologies:iir}
\end{figure}

Some of the generally used types of IIR filters are:
\begin{itemize}\tightlist
    \item
        Butterworth  filter: Named after  the British  engineer and  physicist
        Stephen  Butterworth  (1885  --  1958),  who  first  described  it  in
        1930. Characterized by a very flat passband (no passband ripple).
    \item
        Chebyshev filter  (type I  and II): Named after  Russian mathematician
        Pafnuty Chebyshev  (1821 --  1894). They are steeper  than Butterworth
        filters, at the cost of suffering from ripple in the passband (type I)
        or stopband (type II).
    \item
        Bessel  filter: Named for  the German  mathematician Friedrich  Bessel
        (1784 -- 1846). Optimized to have a maximally linear phase response in
        order  to  minimize the  distortion  of  signals passing  through  the
        filter.
    \item
        Elliptical  filters: Also known  as  Cauer filters,  after the  German
        mathematician Wilhelm Cauer (1900 -- 1945), or Zolotarev filter, after
        Russian mathematician Yegor Zolotarev (1847 -- 1878). Characterized by
        equiripple in the  bassband and stopband and a  very narrow transition
        band compared to other filters of the same order.
\end{itemize}
Digital IIR filters are often designed by way of the bilinear transform.

%>>>
% ==============================================================================
%
%                            F I R   F I L T E R S
%
% ==============================================================================
\subsection{FIR Filters} %<<< ------------------------------------------------ %
\label{subsec:FIR_filters}
% ---------------------------------------------------------------------------- %

FIR filters are  characterized by an impulse response which  decays to zero in
finite time (see  Figure~\ref{fig:filter_specs:coefs}, unlike IIR filters. The
filter response is characterized by Equation~\ref{eq:fir_filter}:

\begin{equation}
    \label{eq:fir_filter}
    H(z) = \sum_{k=0}^{N} b_k \cdot z^{-k}
\end{equation}

FIR filters have several advantages:

\begin{itemize}\tightlist
    \item
        They are inherently BIBO stable because they lack feedback paths.
    \item
        They  can  be  easily  designed  to  have  a  linear  phase  response,
        preventing signal distortion due to  different group delays for signal
        components of different frequencies.
    \item
        The shape of  their frequency response can be  very finely tuned. This
        makes them ideally  suited for certain purposes,  such as compensation
        filters (see Section~\ref{subsec:CIC_filters}).
    \item
        Implementation is usually rather straightforward.
\end{itemize}

Their  main  disadvantage   is  that  due  to  the  lack   of  feedback,  they
generally require comparatively high filter  orders for narrow transition band
widths. Illustratively, this can be understood by the following considerations:
\begin{itemize}\tightlist
    \item
        The frequency response of an ideal low-pass filter is the brick wall
        filter, i.e. a rectangle.
    \item
        The inverse  Fourier transform  of a rectangle  is a  $sinc$ function,
        which is infinitely long.
    \item
        Therefore, the impulse  response of the ideal brick  wall filter would
        have an infinite number of taps.
    \item
        Truncation of the number of taps  leads to a deviation of the filter's
        frequency response from the brick wall  filter.  As the number of taps
        (and  therefore the  FIR filter's  impulse response)  is reduced,  its
        frequency response deviates more and  more from the brick wall filter,
        resulting  in  a  flatter  transition between  the  passband  and  the
        stopband as well as the introduction of ripple.
\end{itemize}

This     process     is     illustrated      in     simplified     form     in
Figure~\ref{fig:brick_wall_vs_FIR}.

The  FIR filter's  transition band  width  is particularly  important for  our
application in order to reduce aliasing effects, as will be shown later.

\begin{figure}
    \centering
    \input{images/brickwallVsFIR/bwVsFIR.tikz}
    \caption[Brick Wall Filter vs. FIR Filter (simplified)]{%
        The effect of  truncating a $sinc$ function in the  time domain on its
        spectrum (simplified)%
    }
    \label{fig:brick_wall_vs_FIR}
\end{figure}

Designing    FIR    filters    is     usually    performed    by    specifying
certain     desired    characteristics     of    the     filter's    frequency
response. Figure~\ref{fig:filter_specs:freqResponse} shows one possible way of
doing this for FIR filters by specifying four constraint parameters:
\begin{itemize}\tightlist
    \item
        pass band ripple: $A_P$
    \item
        stop band attenuation: $A_{St}$
    \item
        pass band edge frequency: $F_P$
    \item
        stop band edge frequency: $F_{St}$
\end{itemize}

The resulting  transition band  width $F_{Tb}$ is  the difference  between the
pass band  edge frequency and  the stop band edge  frequency, and serves  as a
useful indicator of how many coefficients (i.e. resources) the filter will end
up using. Narrower transition bands tend to require a higher filter order, and
therefore  more  resources. Coefficient  counts  of several  hundred  are  not
uncommon for steep FIR filters.

Other sets of  constraint parameters can be used to  design filters, but these
are the ones used in this project, therefore the emphasis on them.

Figure~\ref{fig:filter_specs:coefs}  shows  the   resulting  impulse  response
(coefficient  set)  for  a  FIR  filter  designed  by  using  the  four  above
mentioned parameters, with  values given by Equations~\ref{eq:filter_specs:ap}
through \ref{eq:filter_specs:fst} handed to one  of Matlab's FIR filter design
algorithms.

\begin{align}
    A_P    &= \SI{2}{\dB}   \label{eq:filter_specs:ap}\\
    A_{St} &= \SI{60}{\dB}  \label{eq:filter_specs:ast}\\
    F_P    &= 0.3 \cdot f_s \label{eq:filter_specs:fp}\\
    F_{St} &= 0.4 \cdot f_s \label{eq:filter_specs:fst}
\end{align}

\begin{figure}
    \centering
    \input{images/filterSpecs/freqResponse.tikz}
    \caption[Specifying FIR Filter Constraints]{
        Specifications in the frequency domain and the resulting filter's
        frequency response as designed by Matlab.%
    }
    \label{fig:filter_specs:freqResponse}
\end{figure}

\begin{figure}
    \centering
    \input{images/filterSpecs/coefs.tikz}
    \caption[Impulse Response of a FIR Filter]{
        Impulse    response    (coefficients)     for    the    filter    from
        Figure~\ref{fig:filter_specs:freqResponse}    with   the    parameters
        as     given     by     Equations~\ref{eq:filter_specs:ap}     through
        \ref{eq:filter_specs:fst} passed to one  of Matlab's FIR filter design
        algorithms, resulting  in a set  of \num{39} coefficients.   Note that
        the coefficients to the left and right of these values are zero, hence
        \emph{finite} impulse response filters.%
    }
    \label{fig:filter_specs:coefs}
\end{figure}

Figure~\ref{fig:filtertopologies:fir}   shows   one  possible   topology   for
implementing a  FIR filter,  the so-called  direct form. As  can be  seen, the
basic building  blocks of  a FIR  filter are  delay elements,  multipliers and
adders, same as for IIR filters.

\begin{figure}
    \centering
    \input{images/filtertopologies/fir.tikz}
    \caption[FIR Filter Topology Example]
        {One possible topology for a FIR filter (direct form)}
    \label{fig:filtertopologies:fir}
\end{figure}

One   particular  form   of  a   FIR   filter  is   the  so-called   half-band
filter. Half-band  filters   are  used   for  downsampling   by  a   ratio  of
$R=2$.   They  are  characterized  by  a  point-symmetric  frequency  response
across  the $(f_s/4,0.5)$  point. Their advantage  lies in  the efficiency  of
their  coefficient structure: Each  second coefficient  is zero,  and all  the
non-zero  coefficient  are  symmetrical  around  the  center  of  the  impulse
response. For  higher  downsampling  rates,  multiple  half-band  filters  can
be cascaded. Figure~\ref{fig:fir:halfband_linear_example}  shows the amplitude
frequency response and the coefficient set of an example filter.

\begin{figure}
    \centering
    \input{images/halfband/halfbandLinearExample.tikz}
    \caption[Half-band Filter Frequency Response]{%
        The  frequency response  and coefficient  set of  a half-band  filter.
        The  frequency response  is the  amplitude plotted  linearly, not  the
        magnitude plotted logarithmically, in order to emphasize the symmetry.
        The coefficient  set is  symmetrical around its  midpoint. Also, every
        second coefficient outside the central peak is zero.%
    }
    \label{fig:fir:halfband_linear_example}
\end{figure}
%>>>
% ==============================================================================
%
%                            C I C   F I L T E R S
%
% ==============================================================================
\subsection{CIC Filters} %<<< ------------------------------------------------ %
\label{subsec:CIC_filters}
% ---------------------------------------------------------------------------- %

CIC  filters  were  first  introduced  in 1981  in  \cite{1163535}  by  Eugene
B. Hogenauer. They can be implemented both as decimation filters (reduction in
sampling rate)  and interpolation filters (increase  in sampling rate).

\subsubsection{General Description}
\label{subsubsec:cic:general_description}

A   CIC  filter   is  a   cascade  of   integrator  and   comb  stages,   with
either   a   sampling    rate   compressor   (in   case    of   a   decimator)
or   a    sampling   rate    expander   (in    case   of    an   interpolator)
between   the   integrator   and   comb   sections.    A   single   integrator
stage   is   shown    in   Figure~\ref{fig:filtertopologies:integrator},   and
Figure~\ref{fig:filtertopologies:comb}   shows   a   single  comb   stage   in
feedforward form. Figure~\ref{fig:filtertopologies:cic}  shows a  complete CIC
decimator with three stages.

\begin{figure}
    \centering
    \begin{minipage}[t][][b]{0.45\textwidth}
        \centering
        \input{images/filtertopologies/integrator.tikz}
        \caption[Integrator Stage]{A single integrator stage}
        \label{fig:filtertopologies:integrator}
    \end{minipage}
    \begin{minipage}[t][][b]{0.45\textwidth}
        \centering
        \input{images/filtertopologies/comb.tikz}
        \caption[Comb Stage]{A single comb stage in feedforward form}
        \label{fig:filtertopologies:comb}
    \end{minipage}
\end{figure}

\begin{figure}
    \centering
    \input{images/filtertopologies/cic.tikz}
    \caption[CIC Filter Topology]
        {CIC decimation filter topology with three integrator and comb stages}
    \label{fig:filtertopologies:cic}
\end{figure}

The integrator stages have a transfer function of
\begin{equation}
    \label{eq:cic:integrator_stage}
    H_I(z) = \frac{1}{1-z^{-1}}
\end{equation}

The comb stages run at the reduced frequency of $f_s/R$ and have the transfer
function
\begin{equation}
    \label{eq:cic:comb_stage}
    H_C(z) = 1 - z^{-RM}
\end{equation}
where  $M$  is the  \emph{differential  delay},  one  of the  filter's  design
parameters.

The  transfer function  of  a  complete CIC  filter  (referenced  to the  high
sampling rate  $f_s$) consisting of $N$  stages is deduced by  multiplying the
transfer functions of the $N$ cascaded integrator and comb stages, yielding
\begin{equation}
    \label{eq:cic:complete}
    H_{CIC}(z) = H_I^N(z) \cdot H_C^N(z) =
    \frac{\left(1 - z^{-RM}\right)^N}{\left( 1 - z^{-1} \right)^N} =
    \left[\sum_{k = 0}^{RM-1} z^{-k}\right]^N
\end{equation}

Looking at  the last form  of the CIC  filter's transfer function,  it becomes
evident  that it  is in  essence a  FIR filter  with unitary  coefficients. Of
particular note is the fact that this is so despite each stage having feedback
or feedforward paths and  the integrator stages having poles at  $f = 0$ (i.e.
the integrators  by themselves are  not in fact  BIBO stable, even  though the
complete  system  is). The  fact  that  the  resulting  filter  has  no  poles
can  be  intuitively   understood  by  looking  at   the  frequency  responses
of  the   integrator  and  comb   stages,  and  finally  their   cascade  (see
Section~\ref{subsubsec:cic:frequency_characteristics}).

CIC filters are well-suited to large reductions in sampling rates because they
are very  economical in  their resource  usage. This economy  is based  on six
primary factors (see also \cite{1163535}):
\begin{itemize}\tightlist
    \item
        The filter requires no multipliers.
    \item
        There are no filter coefficients to store.
    \item
        The amount  of storage needed  for intermediate results is  reduced by
        running the comb  stages at a lower sampling  rate. A conventional FIR
        filter topology implementing the  same transfer function would require
        more resources for storing its intermediate results because the entire
        filter would run at the incoming sampling rate.
    \item
        The  topology  of  the  filter   has  a  high  degree  of  regularity;
        consisting of two  primary building blocks. This lends  itself well to
        optimization.
    \item
        The control logic can be kept simple.
    \item
        The  same  filter  design can  be  used  for  a  large range  of  rate
        change  factors $R$,  requiring  minimal  adaption in  circuitry. This
        effect  can be  seen  in the  frequency response  plotted  in the  top
        plot of  Figure~\ref{fig:cic:freq_responses:var}.
\end{itemize}

However, CIC filters do suffer from some drawbacks. The two primary ones are:
\begin{itemize}\tightlist
    \item
        For    large     rate    change    factors    $R$,     the    register
        growth    of     the    filter    can    become     very    large. See
        Section~\ref{subsubsec:cic:register_growth}.
    \item
        A   CIC  filter   has   only  three   design  parameters   determining
        its   frequency  response: Rate   change   factor  $R$,   differential
        delay   $M$,    and   the    number   of   stages    $N$. The   amount
        of   fine-tuning   which   can    be   conducted   on   the   filter's
        frequency   response  is   therefore   extremely   limited  (more   in
        Section~\ref{subsubsec:cic:frequency_characteristics}).
\end{itemize}

As  can  be  seen in  Equation~\ref{eq:cic:integrator_stage},  the  integrator
stages have  unity feedback coefficients. In  the case of CIC  decimators, the
registers of  the integrators  will therefore  suffer from  register overflow.
This causes no harm as long as two conditions are fulfilled:
\begin{itemize}\tightlist
    \item
        The filter's  implementation is based  on two's complement  or another
        number system allowing wrap-around between  its most positive and most
        negative numbers.
    \item
        The maximum  magnitude which is expected  at the output is  within the
        range of that number system.
\end{itemize}

A numerical  example to demonstrate this  effect and better explain  the inner
workings  of a  CIC filter  can be  found in  Appendix~\ref{sec:app:cic_simu},
starting on page~\pageref{sec:app:cic_simu}.

% ==============================================================================
%
%              F R E Q U E N C Y   C H A R A C T E R I S T I C S
%
% ==============================================================================
\subsubsection{Frequency Characteristics} % ---------------------------------- %
\label{subsubsec:cic:frequency_characteristics}
% ---------------------------------------------------------------------------- %

This section presents some of  the more important frequency characteristics of
the  CIC  filter. We  will  start  with  some  considerations  about  how  the
integrators and comb  sections interact in the frequency domain  to create the
CIC filter's frequency response.

As  shown  in  the  topmost plot  in  Figure~\ref{fig:cic:freq_responses},  an
integrator is  in essence a lowpass  filter, with a pole  at $f = 0$.   A comb
filter is  a filter  which attenuates one  specific frequency  component along
with its multiples (in a notch comb  filter; there is also the inverse concept
of a  peak filter  which only  lets a  certain frequency  and multiples  of it
pass).  It is also  evident that comb filters have no poles  (a fact which can
be deduced from Equation~\ref{eq:cic:comb_stage} as well, of course).

Cascading integrators and  combs results in a frequency response  like the one
in the bottom  plot from Figure~\ref{fig:cic:freq_responses}. The integrator's
pole at $f = 0$ compensates for  the comb section's zero at the same location,
leading to a significant, but finite, DC gain of the CIC filter.

One drawback  of CIC  filters is  that they have  no clearly  defined passband
as  such. Rather,  their  frequency  response starts  dropping  off  right  as
the  frequency axis  goes  beyond  zero. This effect  (  also  referred to  as
\emph{passband  droop}  or  \emph{passband  attenuation}) is  visible  in  the
magnified section  of the  bottom plot  in Figure~\ref{fig:cic:freq_responses}
and  in   Figure~\ref{fig:cic:freq_responses:passband:attenuation}. Since  CIC
filters lack  a clearly defined  transition band edge, defining  the frequency
band which  is to  actually be  used, i.e.  the actual  passband, is  a design
decision  and can  vary even  when  using the  same filter,  depending on  the
application.

The  amount  of  passband  droop  is  constant for  a  given  product  of  the
differential  delay $M$  and  the cutoff  frequency $f_c$,  where  $f_c$ is  a
fraction  of the  lower sampling  rate (i.e.  a fraction  of the  first lobe's
width). Figure~\ref{fig:cic:freq_responses:passband:attenuation}    highlights
this  effect  for  two  different  filters. Table~\ref{tab:cic:pb_attenuation}
in                 Appendix~\ref{sec:app:cic_filter_tables}                 on
page~\pageref{tab:cic:pb_attenuation}  contains a  list with  more values  for
some common configurations.

Because  of the  passband droop,  a CIC  filer by  itself is  rarely a  viable
solution. Rather, it is generally deployed as  the first element in a chain of
filters,  where the  later stages  are FIR  filters. Due to  the CIC  filter's
frugality  in terms  of resource  usage, it  is ideally  suited as  an initial
stage, where the most samples per time need to be processed. The fact that FIR
filters need  to perform many  more computations  (and more complex  ones) per
sample is  then no longer as  much of a  problem, since those FIR  filters run
at  lower sampling  frequencies  and  have therefore  many  more clock  cycles
available  to  compute  each  output. Also,  because  the  frequency  response
of  a  FIR  filter can  be  very  finely  tuned  to a  desired  profile,  they
can  be used  to  compensate for  the  CIC filter's  passband  droop; this  is
generally  known as  a \emph{CIC  compensation filter}. More  on the  topic in
Section~\label{subsubsec:cic:compensators}.

Another  effect which  must be  taken  into consideration  when designing  CIC
filters  is  the amount  of  aliasing  which  occurs  from the  stopband  into
the  passband. A  region of  width  $f_c$  above  and  below each  $M$th  null
is  folded  back  into  the  filter's  passband. This  effect  is  highlighted
in  Figure~\ref{fig:cic:freq_responses:passband:aliasing}.    The  gravity  of
this  effect  depends   on  the  width  of  the  cutoff   frequency  $f_c$  as
well   as  the   differential  delay   $M$. Table~\ref{tab:cic:pb_attenuation}
Appendix~\ref{sec:app:cic_filter_tables}  contains  some   values  for  common
ranges for M and $f_c$.

As  mentioned, the  CIC filter  has  only three  design parameters: Its  rate
change factor  $R$, the differential delay  $M$ and the number  of stages $N$.
The influence  of these parameters  on the  CIC filter's frequency  response is
portrayed in Figure~\ref{fig:cic:freq_responses:var}. Some things of note are:
\begin{itemize}\tightlist
    \item
        Increasing $R$  increases the amount of  nulls as well as  the overall
        gain of the filter.
    \item
        Increasing  $M$ also  increases the  number of  nulls as  well as  the
        filter's gain.  Note that for  CIC decimators, the region around every
        $M$th null is folded back into the passband.

        For practical purposes, $M$ is usually  set to \num{1} or \num{2}, see
        \cite{1163535}.
    \item
        Adding more stages leads to a  high increase in filter gain, since $N$
        occurs in the exponent of the filter's transfer function. It does not,
        however, change the number or placement of the nulls.
\end{itemize}

\begin{figure}
    \centering
        \input{images/cic/cicFreqResponses.tikz}
        \caption[Frequency Responses for Integrators, Combs and CIC Filters]{%
            Frequency responses  for integrators, combs and  their combination
            into a three-stage CIC filter with a rate change factor of \num{9}
            and a  differential delay of  \num{1}.  Note that  \num{4.5} lobes
            fit into the plot for the comb  filter, due to $R\cdot M = 9$ (the
            order of the  comb filter).  The enlarged box shows  a close-up of
            the CIC filter's passband droop.%
        }
        \label{fig:cic:freq_responses}
\end{figure}

\begin{figure}
    \centering
        \input{images/cic/cicFreqResponsesVar.tikz}
        \caption[Influence of Design Parameters on Frequency Response]{%
            The influence of  the design parameters $R$, $M$ and  $N$ on a CIC
            filter' frequency response.  Increasing $R$ and $M$, respectively,
            leads to an  increased number of nulls, as visible  in the top two
            plots,  as well  as  an  increase in  the  DC  gain.  Adding  more
            stages does  not change the  location of  the nulls, but  does add
            significant DC gain.%
        }
        \label{fig:cic:freq_responses:var}
\end{figure}

\begin{figure}
    \centering
        \input{images/cic/cicPassbandAttenuation.tikz}
        \caption[CIC Filter: Passband and Aliasing Attenuation]{%
            Passband   attenuation   for   two   CIC   filters   with   $R=9$,
            $N=4$   and  $M=1$   and   $M=2$,  respectively. The   attenuation
            is  identical   for  the  bandwidth-differential   delay  product,
            which   is  $1/8$   for   both  of   these  configurations.    The
            attenuation   is  \SI{-3.65}{\dB}   in  both   cases;  the   value
            can    be   found    in   Table~\ref{tab:cic:pb_attenuation}    on
            page~\pageref{tab:cic:pb_attenuation}.%
        }
        \label{fig:cic:freq_responses:passband:attenuation}
\end{figure}

\begin{figure}
    \centering
        \input{images/cic/cicPassbandAliasing.tikz}
        \caption[CIC Filter: Passband and Aliasing Attenuation]{%
            Passband aliasing for  a CIC filter with $R =  9$, $N=4$ and $M=1$
            and a  cutoff frequency of $f_c  = 0.25$, referenced to  the lower
            sampling frequency $f_\mathrm{s,low}$.  The  region of width $f_c$
            around  every $M$th  null is  folded back  into the  passband. The
            regions beyond that  are of course folded back as  well, but since
            we choose to arbitrarily limit the passband, those regions are not
            of interest to us.  The resulting passband aliasing attenuation is
            \SI{41.8}{\dB}, as indicated in Table~\ref{tab:cic:pb_aliasing} on
            page~\pageref{tab:cic:pb_aliasing}.%
        }
        \label{fig:cic:freq_responses:passband:aliasing}
\end{figure}
% ==============================================================================
%
%                           C O M P E N S A T O R S
%
% ==============================================================================
\subsubsection{Compensators} % ----------------------------------------------- %
\label{subsubsec:cic:compensators}
% ---------------------------------------------------------------------------- %

In     order      to     achieve     a     flat      passband,     the     CIC
filter's    attenuation     in    the    frequency    range     observed    in
Figure~\ref{fig:cic:freq_responses:passband:attenuation}  can  be  compensated
with a filter  whose frequency response has the opposite  shape. Operated in a
cascade  (see Section~\ref{sec:multi_stage_filter_designs}),  the two  filters
create a frequency response with a flat passband and a sharp drop-off into the
stopband. Figure~\ref{fig:cic:cfir} shows  an example  of such a  system, with
frequency  responses of  a  CIC  filter, its  compensator,  and the  resulting
cascade.

The compensation filter not only serves to compensate for the passband, but is
also responsible  for the transition band  width of the cascade. Due  to their
flexibility, FIR filters are generally employed for this purpose. As mentioned
in  the previous  section,  the  sharpness of  their  transition  band can  be
controlled  by  adjusting  their  kernel size. If  the  compensator  has  more
filters  coming after  it in  the overall  filter chain,  its transition  band
need  not be  very narrow. A  filter  with a  few dozen  coefficients in  size
is  often  sufficient in  such  cases  (the filter  used  for  the example  in
Figure~\ref{fig:cic:cfir} has \num{50} coefficients).

The design of CIC compensators is  usually left up to software algorithms, for
example with Matlab. For a more detailed introduction to the topic, including
example  code  and  more  thorough  explanations,  Altera's  Application  Note
from~\cite{altera:an455} is warmly recommended.

\begin{figure}
    \centering
    \input{images/cic/cfirDemo.tikz}
    \caption[CIC Compensator]{%
        Frequency behavior of  a CIC filter, its compensator,  and the cascade
        of the  two. Note the  spectral copies of  the compensator  around the
        nulls of the  CIC filter, i.e. the multiples of  its outgoing sampling
        rate.%
    }
    \label{fig:cic:cfir}
\end{figure}
% ==============================================================================
%
%                        R E G I S T E R   G R O W T H
%
% ==============================================================================
\subsubsection{Register Growth}
\label{subsubsec:cic:register_growth}

As shown by Hogenauer in~\cite{1163535}, the maximum register growth is
\begin{equation}
    \label{eq:cic:maximum_register_growth}
    G_\mathrm{max} = (R \cdot M)^N
\end{equation}
The most  significant bit $B_\mathrm{max}$ of  the output register as  well as
for all  stages (both the  integrators and the comb  stages) of the  filter is
determined to be
\begin{equation}
    \label{eq:cic:maximum_register_growth:bit_width}
    B_\mathrm{max} = \lceil N \log_2 RM + B_\mathrm{in} - 1 \rceil
\end{equation}
where $B_\mathrm{in}$ is  the bit width of the input  register.  For high rate
change  factors, these  values can  become very  large.  A  filter with  three
stages, a  differential delay of  \num{1}, a rate  change of \num{128}  and an
input  width of  \num{16}\,bits  yields  \num{36}\,bits output  width at  full
precision.
% ==============================================================================
%
%         T R U N C A T I O N   A N D   R O U N D I N G   E R R O R S
%
% ==============================================================================
\subsubsection{Errors Due to Truncation and Rounding}
\label{subsubsec:cic:truncation_and_rounding}

In practical cases, it is often not feasible to retain full precision; in such
situations, either truncation or rounding may  be used at each filter stage to
reduce register widths and keep resource usage within certain limits. For this
purpose, it is necessary  to know the system function from  the $j$th stage up
to and including the last:
\begin{equation}
    \label{eq:cic:truncation_rounding:system_function}
    H_j(z) = \left\lbrace
        \begin{aligned}
            H_I^{N-j+1}H_C^N                        &
            = \sum_{k=0}^{(RM-1)N+j-1} h_j[k]z^{-k} &
            \quad j                                 &
            = 1, 2, \cdots, N                       \\
            H_C^{j-N}                                          &
            = \hspace{1.1em}\sum_{k=0}^{2N+1-j} h_j[k]z^{-kRM} &
            \quad j                                            &
            = N+1, \cdots, 2N
        \end{aligned}
    \right.
\end{equation}
where
\begin{equation}
    \label{eq:cic:truncation_rounding:system_function}
    h_j[k] = \left\lbrace
        \begin{aligned}
            \sum_{l=0}^{\lfloor k/(RM) \rfloor} (-1)^l
            {{N}\choose{l}}{{N-j+k-RMl}\choose{k = RMl}} &
            j                                            &
            = 1, 2, \cdots N                             \\
            (-1)^k{{2N+1-j}\choose{k}} &
            j                          &
            = N+1, \cdots 2N
        \end{aligned}
    \right.
\end{equation}
are the  impulse response  coefficients. These functions  are also  derived by
Hogenauer in~\cite{1163535}.

In a  filter with $N$ stages,  there are $2N+1$  error sources in the  case of
limited precision: Each stage,  and the output register. Each  error source is
presumed to have  white noise characteristics, i.e. its  noise is uncorrelated
to its input as well as other error sources.  The error at the $j$th source is
assumed to have a uniform probability distribution with a width of
\begin{equation}
    \label{eq:cic:truncation_rounding:probability_distribution}
    E_j = \left\lbrace
        \begin{aligned}
            0        & \quad\text{without truncation or rounding}\\
            2^{B_j}  & \quad\text{otherwise}
        \end{aligned}
    \right.
\end{equation}
where the number of bits discarded at the $j$th error source is $B_j$. The mean
of this error is
\begin{equation}
    \label{eq:cic:truncation_rounding:mean}
    \mu_j = \left\lbrace
        \begin{aligned}
            \frac{1}{2}E_j & \quad\text{for truncation}\\
            0              & \quad\text{otherwise}
        \end{aligned}
    \right.
\end{equation}
and the variance comes out to
\begin{equation}
    \label{eq:cic:truncation_rounding:variance}
    \sigma_j^2 = \frac{1}{12}E_j^2.
\end{equation}

The total mean error at the filter's output due to the $j$th stage is
\begin{equation}
    \label{eq:cic:truncation_rounding:total_mean_error_jth_stage}
    \mu_{T_j} = \mu_jD_j
\end{equation}
where
\begin{equation}
    \label{eq:cic:truncation_rounding:mean_error_gain}
    D_j = \left\lbrace
        \begin{aligned}
            (RM)^N         & \quad j = 1\\
            0              & \quad j = 2, 3, \cdots, 2N\\
            1              & \quad j = 2N+1
        \end{aligned}
    \right.
\end{equation}
is the \emph{mean  error gain} for the $j$th error  source. Note that only the
first and the last  error source contribute to the filter's  mean error at the
output. This is because  the sum of the impulse response  coefficients is zero
for all other  stages. Consequently, whether one chooses to  truncate or round
is  without  consequence except  in  the  case of  the  first  and last  error
sources. In an analogous manner, the total variance computes to
\begin{equation}
    \label{eq:cic:truncation_rounding:total_variance_jth_stage}
    \sigma_{T_j}^2 = \sigma_j^2F_j^2
\end{equation}
where
\begin{equation}
    \label{eq:cic:truncation_rounding:variance_error_gain}
    F_j = \left\lbrace
        \begin{aligned}
            \sum_k h_j^2[k]  & \quad j = 1, 2, \cdots, 2N\\
            1                & \quad j = 2N+1
        \end{aligned}
    \right.
\end{equation}
is called the \emph{variance error gain} for the $jth$ error source.

We can now compute the global mean error and variance of the filter:
\begin{align}
    \label{eq:cic:truncation_rounding:global:mean_error}
    \mu_T &= \sum_{j = 1}^{2N+1} \mu_{T_j} = \mu_{T_1} + \mu_{T_{2N+1}}\\
    \label{eq:cic:truncation_rounding:global:variance}
    \sigma_{T}^2 &= \sum_{j=1}^{2N+1} \sigma_{T_j}
\end{align}
These equations  are used  to calculate  the properties of  the CIC  filter as
deployed in our design, see Section~\ref{subsec:fpga:errors_in_cic_filter}.

% ==============================================================================
%
%                   C I C   F I L T E R S :   S U M M A R Y
%
% ==============================================================================
\subsubsection{Summary}
\label{subsubsec:cic:summary}

In conclusion, the key properties of CIC filters are:
\begin{itemize}\tightlist
    \item
        They can be implemented both as decimators and interpolators.
    \item
        Neither multipliers nor storage for coefficients are needed.
    \item
        CIC  decimation  filters have  a  high  gain, leading  to  significant
        register  growth.  Truncation  or rounding  can be  used to  limit the
        resource usage, both at the filter's output and internally.
    \item
        The three design parameters are  the rate change $R$, the differential
        delay $M$ and the number of stages $N$.
    \item
        The  presence of  passband  droop requires  a  compensation filter  to
        achieve a flat passband response.
\end{itemize}
%>>>

%>>>

% ==============================================================================
%
%             M U L T I - S T A G E   F I L T E R   D E S I G N S
%
% ==============================================================================
\section{Multi-Stage Filter Designs} % <<< ----------------------------------- %
\label{sec:multi_stage_filter_designs}
% ---------------------------------------------------------------------------- %

At  first   sight,  the   most  obvious  way   to  implement   a  downsampling
system  might  appear  to be  to  design  one  filter  for each  desired  rate
change   factor.   However,   this  would   be  highly   impractical. Instead,
multi-stage  designs  are usually  used  in  practice. An in-depth  discussion
of  their  advantages and  drawbacks  was  offered  by Crochiere  and  Rabiner
in~\cite{crochiere-rabiner:multirate-dsp}. A few aspects of multi-stage filter
design which are relevant to our application shall be presented here.

To  reduce  aliasing  effects  in  the passband,  it  is  generally  desirable
to  keep  the width  of  the  transition  band  roughly constant  in  relation
to  the   width  of   the  passband   (visible  in   the  filter's   flank  in
Figure~\ref{fig:aliasing:iirCopies}).   As  the downsampling  ratio  increases
and  the  passband width  decreases,  the  transition band  therefore  becomes
progressively narrower,  necessitating higher filter orders  in a single-stage
design.

This   effect  is   illustrated  in   Figure~\ref{fig:fdesign:tbw_width_Rvar},
comparing two filters with a transition band $1/5$ as wide as the passband for
downsampling  ratios of  \num{2} and  \num{4}. The filter  for $R=4$  requires
\num{60}  coefficients,  compared  to  \num{30} coefficients  for  the  filter
designed  for $R=2$.   The other  specifications (passband  ripple, stop  band
attenuation) are identical.   As an extreme case, a filter  designed by Matlab
with the  same parameters for  a downsampling  ratio of $R=625$  is \num{8860}
coefficients in size.

Using multi-stage  designs helps to avoid  the need to implement  filters with
such large kernels.  When cascading filters, it is the last stage of the chain
which defines the overall passband and transition band width. The same overall
transition band  in absolute  terms can  be achieved  with smaller  filters in
multi-stage designs, because  a filter's transition band width  is relative to
the sampling rate at which it is running.  This is shown in the bottom plot in
Figure~\ref{fig:fdesign:tbw_width_Rvar}.

\begin{figure}
    \centering
    \input{images/fdesign/tbwDemoRVar.tikz}
    \caption
        [Frequency Response of Multi-Stage Vs. Single-Stage Design]{%
        Two filters are  used here: Both have a transition band  $1/5$ as wide
        as  their passbands. The  top filter  is designed  for a  downsampling
        ratio $R=2$ and  has a coefficient count of  $N=30$. The second filter
        is designed for $R=4$ and  has \num{60} coefficients. Cascading two of
        the top filters into a two-stage  design, depicted in the bottom plot,
        results in the same overall passband  and transition band width as the
        single-stage design.%
    }
    \label{fig:fdesign:tbw_width_Rvar}
\end{figure}

Since  cascading  multiple  filters   does  increase  coefficient  count  (and
storage), one might  be inclined to think that not  much has been won. Indeed,
the  overall  number  of  coefficients   is  identical  for  both  filters  in
Figure~\ref{fig:fdesign:tbw_width_Rvar}  (though, this  obviously need  not be
so  in  other  examples). However: Merely \num{30}  multipliers  and  \num{29}
adders  (those  of the  first  filter  in the  cascade)  run  at the  incoming
sampling  frequency in  the  case  of the  cascade,  while  the components  of
the  second  filter  run at  half  that.   In  the  case of  the  single-stage
filter,  all  its  \num{60}  multipliers   and  \num{59}  adders  run  at  the
full  sampling frequency. Distributing  the calculations  over two  stages has
therefore yielded  an overall reduction  in needed computation  power. As rate
change  factors increase,  the  benefits of  multi-stage  designs become  even
more pronounced~\cite{crochiere-rabiner:multirate-dsp}. 

In general, the  earlier stages in a cascade tend  to have higher downsampling
ratios  but  wider   transition  bands,  and  the  later   stages  have  lower
downsampling  ratios  and  narrower  transition  bands  (normalized  to  their
respective  sampling frequencies).   This  minimizes  computations across  the
overall design by  using smaller filters for  high-frequency calculations, and
giving the larger filters more  time to compute their outputs. Multiple stages
having the  same downsampling  ratios is  also a  valid approach,  but earlier
stages having lower downsampling ratios than later stages is uncommon.

Another advantage of  cascading filters is that successive stages  can be used
to  shape the  overall frequency  response, as  seen in  the case  of the  CIC
compensator in Section~\ref{subsubsec:cic:compensators} A drawback of cascades
is that the ripple in their passband shows additive behavior, so the stages in
a cascade of  filters have more stringent ripple requirements  in the passband
then  a single-stage. However,  the cost  for this  is usually  offset by  the
advantages of multi-stage designs.

When designing multi-stage filters, it can  happen that the transition band of
an earlier stage overlaps with the spectral copy of a later stage running at a
reduced sampling rate.  In that case, the stopband response of the cascade can
have  peaks exceeding  the  desired overall  stopband attenuation. To  prevent
this, the following condition must be satisfied:
\begin{equation}
    \label{eq:cascade:transition_band_overlap}
    f_\mathrm{st,1} < \frac{f_\mathrm{s,1} - f_\mathrm{st,2}}{R_1}
\end{equation}
\begin{conditions}
    f_\mathrm{s,1}  & high sampling rate                  \\
    f_\mathrm{st,1} & stopband frequency of first filter  \\
    f_\mathrm{st,2} & stopband frequency of second filter \\
    R_1             & rate reduction in first filter      \\
\end{conditions}
Figure~\ref{fig:fdesign:cascade:good_vs_bad}  shows  some  examples  for  this
condition being broken or fulfilled.

\begin{figure}
    \centering
    \input{images/fdesign/cascadeDemo.tikz}
    \caption[Cascade: Transition Band Overlap]{%
        Comparison   of   two   cascades: The   first   cascade   (blue)   has
        sufficient  distance   between  the  start  of   its  stopband  ($0.65
        \cdot  f_\mathrm{s1}$)  and  the  start  of  the  transition  band  of
        the  second stage's  first copy  around $f_\mathrm{s2}$  ($0.675 \cdot
        f_\mathrm{s1}$). The  second  cascade  (orange)  has  a  peak  in  its
        stopband because the transition band  of its first stage overlaps with
        the  copy of  the second  stage ($0.8  \cdot f_\mathrm{s1}$  vs.  $0.6
        \cdot f_\mathrm{s1}$). \emph{Note:} All  frequencies are referenced to
        the high sampling rate $f_\mathrm{s1}$.%
    }
    \label{fig:fdesign:cascade:good_vs_bad}
\end{figure}

One last effect of note when cascading filters concerns stopband attenuation:
When cascading two filters with different stopband attenuations, two things
can happen:
\begin{itemize}\tightlist
    \item
        The second  filter attenuates more  strongly than the  first one. This
        results  in  peaks  above  the second  filter's  stopband  attenuation
        in  the regions  where  the  spectral copies  of  the second  filter's
        passband  are   located. This  can  be   seen  in  the  top   plot  in
        Figure~\ref{fig:fdesign:cascade:ast_demo}.
    \item
        The first filter attenuates more  strongly than the first one. In that
        case, the stopband region of the  cascade right next to its transition
        band is  less strongly  attenuated than  the stopband  regions farther
        away  from  the  edge. This  case  is shown  in  the  middle  plot  in
        Figure~\ref{fig:fdesign:cascade:ast_demo}.
\end{itemize}
Either  of  these  two  effects   is  usually  not  desired,  barring  special
scenarios. In both  cases, the  resources invested  into the  steeper filter's
stronger  attenuation  are  wasted  by  the  other  filter's  weaker  stopband
attenuation. It therefore makes more sense for the various stages in a cascade
to have the same stopband attenuation, in general.

\begin{figure}
    \centering
    \input{images/fdesign/astDemo.tikz}
    \caption[Cascade: Stopband Attenuation]{%
        Cascading  two  filters  with different  stopband  attenuations: If  a
        filter with stronger  stopband attenuation is cascaded  after a filter
        with weaker  attenuation, the  resultant cascade  has peaks  above the
        second  filter's  stopband  attenuation (top  plot). If  the  stronger
        filter is  first in the  cascade, the  drop-off in the  stopband right
        next to the  transition band is weaker. The two  filters by themselves
        are shown in the bottom plots.%
    }
    \label{fig:fdesign:cascade:ast_demo}
\end{figure}

%>>>

%^^A vim: foldenable foldcolumn=4 foldmethod=marker foldmarker=<<<,>>>
